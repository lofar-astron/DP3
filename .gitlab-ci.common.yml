# Copyright (C) 2024 ASTRON (Netherlands Institute for Radio Astronomy)
# SPDX-License-Identifier: GPL-3.0-or-later

workflow:
  rules:
    # don't create a pipeline if its a commit pipeline, on a branch and that branch has open merge requests.
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS
      when: never
    - when: always

variables:
  GIT_SUBMODULE_STRATEGY: recursive

.failable:
  retry:
    max: 1
    when:
      - runner_system_failure
      - stuck_or_timeout_failure

stages:
  - prepare
  - build
  - linting
  - test
  - publish
  - scan
  - pages

include: .gitlab-ci.wheels.yml

# Creating a docker image name which includes the commit hash of the dockerfile,
# and storing that image name in a 'dotenv' artifact, allows reusing docker
# images between different pipelines.
# See https://confluence.skatelescope.org/display/SE/Caching+Docker+images+using+GitLab+CI+registry
.prepare:
  extends: [".failable",".dind"]
  stage: prepare
  image: docker:29.0
  before_script:
    - apk add git
    - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $CI_REGISTRY
  script:
    # Unshallowing ensures that 'git log' works
    - git fetch --unshallow
    - DOCKER_FILE=docker/ubuntu_${UBUNTU_VERSION}_04_base
    - DOCKER_FILE_COMMIT=$(git log -n 1 --pretty=format:%H -- ${DOCKER_FILE})
    - DOCKER_IMAGE=${CI_REGISTRY_IMAGE}/base_ubuntu${UBUNTU_VERSION}:${DOCKER_FILE_COMMIT}
    - echo BASE_IMAGE_${UBUNTU_VERSION}04=${DOCKER_IMAGE} > base_image.env
    - cat base_image.env
    - |
      if ! docker manifest inspect $DOCKER_IMAGE > /dev/null || [ "$BUILD_DOCKER_IMAGE" = "1" ]; then
        if [ "$BUILD_DOCKER_IMAGE" = "1" ]; then
          DOCKER_CACHE_PARAMETERS="--no-cache"
        else
          DOCKER_CACHE_PARAMETERS=""
        fi
        docker build $DOCKER_BUILD_ARG ${DOCKER_CACHE_PARAMETERS} --tag $DOCKER_IMAGE -f $DOCKER_FILE .
        docker push $DOCKER_IMAGE
      fi
  artifacts:
    reports:
      dotenv: base_image.env
  # Skip the job if there are no changes to the Docker file. This shortcut only
  # works for push and merge request jobs.
  # A manual pipeline run will thus create missing docker images.
  #
  # This is disabled since the detections of the changes by GitLab seems flaky.
  # TODO(AST-887) Reenable this to test whether it's no longer flaky.
  #
  #rules:
  #  - changes:
  #    - $DOCKER_FILE

# Create and push the base image to the gitlab registry, if it does not exist.
prepare-base-2204:
  extends: .prepare
  variables:
    UBUNTU_VERSION: 22

prepare-base-2404:
  extends: .prepare
  variables:
    UBUNTU_VERSION: 24

# Template for jobs that depend on prepare-base-2204.
.needs-base-2204:
  needs: ["prepare-base-2204"]
  image: $BASE_IMAGE_2204

# Template for jobs that depend on prepare-base-2404.
.needs-base-2404:
  needs: ["prepare-base-2404"]
  image: $BASE_IMAGE_2404

# Template for basic build jobs.
.build-basic:
  extends: .failable
  stage: build
  script:
    - if [ -d /dp3env ]; then source /dp3env/bin/activate; fi
    - mkdir build && cd build
    - cmake ${CMAKE_FLAGS} -G Ninja ..
    - ninja -j4 install
    - DP3

# Test DP3 builds and runs without optional dependencies (IDG) installed.
# Specifically on the Haswell architecture, which also tests setting the
# TARGET_CPU option.
build-2404-no-idg-target-cpu:
  extends: [".needs-base-2404", ".build-basic"]
  before_script:
    # Remove IDG, so DP3 can't and won't use it.
    - rm /usr/include/idg-*.h /usr/lib/libidg-*
    - rm /usr/lib/cmake/idg-*.cmake /usr/lib/cmake/IDGAPI*.cmake
  variables:
    CMAKE_FLAGS: -DTARGET_CPU=haswell

# Build (and run) DP3 on Ubuntu 24, ensuring compatibility with new systems.
# This build also tests building DP3 with the PORTABLE option.
build-2404-portable:
  extends: [".needs-base-2404", ".build-basic"]
  variables:
    # Enable tests and thereby check if they also compile on new systems.
    CMAKE_FLAGS: -DBUILD_TESTING=On -DPORTABLE=On

build-doc-2404:
  stage: build
  extends: [".failable",".needs-base-2404"]
  before_script:
    # Install here since pytest and these items aren't compatible
    - /dp3env/bin/pip install autosemver jsonschema2rst myst_parser sphinx sphinx-rtd-theme
    # Patch to make 'doc' settings not be parsed as code. Make sure to apply this patch also in .readthedocs.yml!
    - patch -p0 /dp3env/lib/python3.12/site-packages/jsonschema2rst/rst_utils.py < docs/rst_utils.py.patch
  script:
    - source /dp3env/bin/activate
    - mkdir build && cd build
    - cmake -G Ninja ../docs
    - ninja doc userdoc
  artifacts: # Only for master the docs are published; for branches it may be useful to browse the artifacts
    paths:
    - build/docs

build-package-2204:
  stage: build
  extends: [".failable",".needs-base-2204"]
  script:
    - mkdir dp3_package
    - mkdir build && cd build
    - git fetch --unshallow # We need to unshallow for the tags (setting GIT_DEPTH is not good enough)
    - cmake -DBUILD_PACKAGES=On ..
    - make -j4
    - make package
    - mv $(ls -1 *.deb) ../dp3_package/
  artifacts:
    paths:
    - dp3_package/
  rules:
    # The package is built only during a merge_request_event, a merge to master,
    # or when the pipeline is triggered by a tag event.
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_COMMIT_BRANCH == "master"'
    - if: '$CI_COMMIT_TAG'
    - if: '$UPLOAD_PACKAGE'

linting-2404:
  stage: linting
  extends: [".failable",".needs-base-2404"]
  before_script:
    - pipx install black~=24.0 clang-format~=14.0 cmakelang isort
    - ln -s $(which clang-format) $(which clang-format)-14
  script:
    - ./scripts/run-format.sh

# The tests require Sisco, which again requires a recent version of
# libdeflate only available since Ubuntu 24.
test-2404:
  stage: test
  extends: [".failable",".needs-base-2404"]
  script:
    - source /dp3env/bin/activate
    - export PYTHONPATH=${PYTHONPATH}:/usr/local/lib/python3.10/dist-packages
    - mkdir build && cd build
    - cmake -G Ninja -DCMAKE_BUILD_TYPE=Debug -DBUILD_TESTING=On ..
    - ninja -j4
    - ctest --output-on-failure --no-tests=error -j$(nproc)
  artifacts:
    paths:
      - build/unittest*.xml
      - build/pytest_*.xml
    reports:
      junit:
        - build/unittest*.xml
        - build/pytest_*.xml

# Use a separate job for collecting code coverage, which uses a Release build,
# since collecting code coverage in a Debug build results in low performance.
# Especially -fprofile-update=atomic makes the tests slow.
# (A single Debug+coverage job takes longer than the total runtime of
#  the current test-2404 and coverage-2404 jobs. It may even time out.)
# The code coverage figures include both unit and integration tests.
#
# The coverage target sets METADATA_COMPRESSION_DEFAULT and USE_FAST_PREDICT whereas
# most other targets don't do this. This way, both settings are tested.
coverage-2404:
  stage: test
  extends: [".failable",".needs-base-2404"]
  script:
    - source /dp3env/bin/activate
    - mkdir build && cd build
    - cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -DBUILD_TESTING=On -DCMAKE_CXX_FLAGS="-coverage -fprofile-update=atomic" -DCMAKE_EXE_LINKER_FLAGS="-coverage" -DMETADATA_COMPRESSION_DEFAULT=True -DUSE_FAST_PREDICT=On ..
    - ninja -j4
    - ctest --output-on-failure --no-tests=error -j$(nproc)
    # Collect coverage in text, xml and json formats.
    - gcovr -j$(nproc) -r ../ -e '.*/external/.*' -e '_deps/.*' -e '.*/test/.*' -e '.*/CompilerIdCXX/.*' --txt --xml coverage.xml --json coverage.json .
  coverage: /^TOTAL.*\s+(\d+\%)$/
  artifacts:
    paths:
      # The pages and collect-metrics jobs need coverage files. See .gitlab-ci.ska.yml.
      - build/coverage.xml
      - build/coverage.json
      - build/unittest*.xml
      - build/pytest_*.xml
    reports:
      junit:
        - build/unittest*.xml
        - build/pytest_*.xml
      coverage_report:
        coverage_format: cobertura
        path: build/coverage.xml

.sanitizer-2404:
  stage: test
  extends: [".failable",".needs-base-2404"]
  script:
    - source /dp3env/bin/activate
    - mkdir build && cd build
    - cmake -G Ninja -DCMAKE_BUILD_TYPE=Debug -DBUILD_TESTING=On -DPORTABLE=Off -DCMAKE_CXX_FLAGS="${CXX_FLAGS}" ..
    - ninja -j4
    # Don't run slow tests. The overhead of the sanitizer causes time outs.
    - ctest --output-on-failure --no-tests=error -j$(nproc) -L unit -LE slow
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: always
      allow_failure: false
    - when: manual
      allow_failure: true

unit-test-address-sanitizer-2404:
  extends: [".sanitizer-2404",".dind"]
  variables:
    CXX_FLAGS: -fsanitize=address
    # Ignore the leaks in third-party libraries.
    LSAN_OPTIONS: suppressions=../ci/address_sanitizer_suppressions.txt

# There are NULL pointer issues in Casacore which blocks testing on CI.
unit-test-undefined-behaviour-sanitizer-2404:
  extends: .sanitizer-2404
  variables:
    CXX_FLAGS: -fsanitize=undefined -fno-sanitize=null -fno-sanitize-recover

deploy-package-2204:
  stage: publish
  needs: ["prepare-base-2204","build-package-2204"]
  image: $BASE_IMAGE_2204
  script:
    - pip3 install aptly-api-client
    - chmod -R 700 external/schaap-packaging
    - cd dp3_package
    - export FILES=$(ls -1 $PWD/*.deb)
    - echo UPLOADING files $FILES
    # The following example command must be executed first or else the update will fail because there is no repository
    # create_repo.py -a amd64 -c testing -d bionic --gpg-key ${GPG_KEY} --gpg-passphrase ${GPG_PASS} schaap
    - ../external/schaap-packaging/update_repo.py --cleanup -d bionic --gpg-key ${GPG_KEY} --gpg-passphrase ${GPG_PASS} schaap ${FILES}
  rules:
    # Only run on master because GPG_KEY and GPG_PASS are protected and therefore only available on protected branches.
    - if: '$CI_COMMIT_BRANCH != "master"'
      when: never
    - if: '$UPLOAD_PACKAGE'
